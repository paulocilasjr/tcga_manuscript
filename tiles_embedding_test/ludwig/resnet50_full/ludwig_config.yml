preprocessing:
    sample_ratio: 1.0  # Use the full dataset (100% of the data)
    sample_size: null  # No size limitation on samples
    oversample_minority: null  # Do not apply oversampling to minority class
    undersample_majority: null  # Do not apply undersampling to majority class
    split:
        type: hash
        column: sample_name
        probabilities:
        - 0.7  # Training split
        - 0.1  # Validation split
        - 0.2  # Test split

input_features:
  - name: merged_vector  # Column storing paths to .txt files with vectors
    type: vector  # Input is pre-trained embeddings
    preprocessing:
      normalization: true  # Normalize vectors
    encoder:
      type: dense  # Use embeddings directly, no additional encoding

output_features:
  - name: label  # Column with target labels
    type: binary  # Binary classification
    metrics:
      - accuracy
      - recall
      - precision
      - specificity

trainer:
  epochs: 10  # Increased to allow more learning iterations
  batch_size: 256  # Increased for efficiency with large dataset
  learning_rate: 0.001  # Increased for faster convergence
  optimizer:
    type: adam  # Retained as a good default
  learning_rate_scheduler:
    type: reduce_on_plateau  # Reduce learning rate on plateau
    metric: roc_auc  # Aligned with validation metric
    patience: 15  # Wait 15 epochs before reducing learning rate
    reduce_rate: 0.5  # Halve the learning rate when triggered
  validation_field: label  # Field for validation
  validation_metric: roc_auc  # Metric for validation
  early_stop: 5  # Stop after 5 epochs with no improvement
