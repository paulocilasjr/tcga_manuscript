Setting random seed to 42
Using device: cuda
Loading data for split 0 from ./../../../trident/TCGA_BRCA/tcga_patches_ludwig.csv
Parsing embeddings for split 0
Normalizing embeddings for split 0
Dataset for split 0 ready with 332997 samples
Loading data for split 1 from ./../../../trident/TCGA_BRCA/tcga_patches_ludwig.csv
Parsing embeddings for split 1
Normalizing embeddings for split 1
Dataset for split 1 ready with 47572 samples
Loading data for split 2 from ./../../../trident/TCGA_BRCA/tcga_patches_ludwig.csv
Parsing embeddings for split 2
Normalizing embeddings for split 2
Dataset for split 2 ready with 163101 samples
Train dataset size: 332997
Validation dataset size: 47572
Test dataset size: 163101
Input dimension: 1536
Model initialized and moved to cuda
Optimizer and scheduler initialized with learning rate: 0.0001
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.1057
Batch 20000/83250 completed, running loss: 0.0789
Batch 30000/83250 completed, running loss: 0.0667
Batch 40000/83250 completed, running loss: 0.0592
Batch 50000/83250 completed, running loss: 0.0544
Batch 60000/83250 completed, running loss: 0.0508
Batch 70000/83250 completed, running loss: 0.0477
Batch 80000/83250 completed, running loss: 0.0451
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 1/50
Train Loss: 0.0443, Train Acc: 0.9830
Val Loss: 0.0221, Val Acc: 0.9917, ROC-AUC: 0.9997
Learning rate after epoch 1: 0.0001
Saved best model with ROC-AUC: 0.9996913417817989
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0204
Batch 20000/83250 completed, running loss: 0.0205
Batch 30000/83250 completed, running loss: 0.0203
Batch 40000/83250 completed, running loss: 0.0201
Batch 50000/83250 completed, running loss: 0.0202
Batch 60000/83250 completed, running loss: 0.0201
Batch 70000/83250 completed, running loss: 0.0198
Batch 80000/83250 completed, running loss: 0.0196
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 2/50
Train Loss: 0.0195, Train Acc: 0.9928
Val Loss: 0.0172, Val Acc: 0.9937, ROC-AUC: 0.9998
Learning rate after epoch 2: 0.0001
Saved best model with ROC-AUC: 0.9998151377520381
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0128
Batch 20000/83250 completed, running loss: 0.0138
Batch 30000/83250 completed, running loss: 0.0138
Batch 40000/83250 completed, running loss: 0.0139
Batch 50000/83250 completed, running loss: 0.0139
Batch 60000/83250 completed, running loss: 0.0139
Batch 70000/83250 completed, running loss: 0.0138
Batch 80000/83250 completed, running loss: 0.0138
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 3/50
Train Loss: 0.0138, Train Acc: 0.9949
Val Loss: 0.0151, Val Acc: 0.9948, ROC-AUC: 0.9999
Learning rate after epoch 3: 0.0001
Saved best model with ROC-AUC: 0.9998589232935347
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0095
Batch 20000/83250 completed, running loss: 0.0101
Batch 30000/83250 completed, running loss: 0.0101
Batch 40000/83250 completed, running loss: 0.0103
Batch 50000/83250 completed, running loss: 0.0103
Batch 60000/83250 completed, running loss: 0.0105
Batch 70000/83250 completed, running loss: 0.0106
Batch 80000/83250 completed, running loss: 0.0109
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 4/50
Train Loss: 0.0109, Train Acc: 0.9960
Val Loss: 0.0131, Val Acc: 0.9948, ROC-AUC: 0.9999
Learning rate after epoch 4: 0.0001
Saved best model with ROC-AUC: 0.999891803636445
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0080
Batch 20000/83250 completed, running loss: 0.0086
Batch 30000/83250 completed, running loss: 0.0086
Batch 40000/83250 completed, running loss: 0.0086
Batch 50000/83250 completed, running loss: 0.0085
Batch 60000/83250 completed, running loss: 0.0086
Batch 70000/83250 completed, running loss: 0.0088
Batch 80000/83250 completed, running loss: 0.0089
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 5/50
Train Loss: 0.0090, Train Acc: 0.9968
Val Loss: 0.0155, Val Acc: 0.9944, ROC-AUC: 0.9999
Learning rate after epoch 5: 0.0001
Early stop counter: 1/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0073
Batch 20000/83250 completed, running loss: 0.0072
Batch 30000/83250 completed, running loss: 0.0072
Batch 40000/83250 completed, running loss: 0.0074
Batch 50000/83250 completed, running loss: 0.0074
Batch 60000/83250 completed, running loss: 0.0075
Batch 70000/83250 completed, running loss: 0.0076
Batch 80000/83250 completed, running loss: 0.0075
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 6/50
Train Loss: 0.0075, Train Acc: 0.9973
Val Loss: 0.0169, Val Acc: 0.9951, ROC-AUC: 0.9999
Learning rate after epoch 6: 0.0001
Early stop counter: 2/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0055
Batch 20000/83250 completed, running loss: 0.0059
Batch 30000/83250 completed, running loss: 0.0061
Batch 40000/83250 completed, running loss: 0.0058
Batch 50000/83250 completed, running loss: 0.0059
Batch 60000/83250 completed, running loss: 0.0060
Batch 70000/83250 completed, running loss: 0.0061
Batch 80000/83250 completed, running loss: 0.0061
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 7/50
Train Loss: 0.0061, Train Acc: 0.9978
Val Loss: 0.0129, Val Acc: 0.9956, ROC-AUC: 0.9999
Learning rate after epoch 7: 0.0001
Saved best model with ROC-AUC: 0.9999192854100425
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0049
Batch 20000/83250 completed, running loss: 0.0053
Batch 30000/83250 completed, running loss: 0.0051
Batch 40000/83250 completed, running loss: 0.0052
Batch 50000/83250 completed, running loss: 0.0054
Batch 60000/83250 completed, running loss: 0.0052
Batch 70000/83250 completed, running loss: 0.0053
Batch 80000/83250 completed, running loss: 0.0054
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 8/50
Train Loss: 0.0054, Train Acc: 0.9981
Val Loss: 0.0165, Val Acc: 0.9948, ROC-AUC: 0.9999
Learning rate after epoch 8: 0.0001
Early stop counter: 1/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0043
Batch 20000/83250 completed, running loss: 0.0047
Batch 30000/83250 completed, running loss: 0.0046
Batch 40000/83250 completed, running loss: 0.0046
Batch 50000/83250 completed, running loss: 0.0048
Batch 60000/83250 completed, running loss: 0.0048
Batch 70000/83250 completed, running loss: 0.0049
Batch 80000/83250 completed, running loss: 0.0049
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 9/50
Train Loss: 0.0049, Train Acc: 0.9983
Val Loss: 0.0167, Val Acc: 0.9951, ROC-AUC: 0.9999
Learning rate after epoch 9: 0.0001
Early stop counter: 2/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0035
Batch 20000/83250 completed, running loss: 0.0038
Batch 30000/83250 completed, running loss: 0.0039
Batch 40000/83250 completed, running loss: 0.0042
Batch 50000/83250 completed, running loss: 0.0041
Batch 60000/83250 completed, running loss: 0.0041
Batch 70000/83250 completed, running loss: 0.0041
Batch 80000/83250 completed, running loss: 0.0042
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 10/50
Train Loss: 0.0042, Train Acc: 0.9986
Val Loss: 0.0165, Val Acc: 0.9956, ROC-AUC: 0.9999
Learning rate after epoch 10: 0.0001
Early stop counter: 3/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0042
Batch 20000/83250 completed, running loss: 0.0040
Batch 30000/83250 completed, running loss: 0.0039
Batch 40000/83250 completed, running loss: 0.0039
Batch 50000/83250 completed, running loss: 0.0041
Batch 60000/83250 completed, running loss: 0.0039
Batch 70000/83250 completed, running loss: 0.0040
Batch 80000/83250 completed, running loss: 0.0039
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 11/50
Train Loss: 0.0039, Train Acc: 0.9987
Val Loss: 0.0145, Val Acc: 0.9960, ROC-AUC: 0.9999
Learning rate after epoch 11: 0.0001
Saved best model with ROC-AUC: 0.999919645905155
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0025
Batch 20000/83250 completed, running loss: 0.0033
Batch 30000/83250 completed, running loss: 0.0032
Batch 40000/83250 completed, running loss: 0.0036
Batch 50000/83250 completed, running loss: 0.0035
Batch 60000/83250 completed, running loss: 0.0035
Batch 70000/83250 completed, running loss: 0.0036
Batch 80000/83250 completed, running loss: 0.0035
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 12/50
Train Loss: 0.0036, Train Acc: 0.9989
Val Loss: 0.0157, Val Acc: 0.9959, ROC-AUC: 0.9999
Learning rate after epoch 12: 0.0001
Saved best model with ROC-AUC: 0.999921187088191
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0019
Batch 20000/83250 completed, running loss: 0.0025
Batch 30000/83250 completed, running loss: 0.0028
Batch 40000/83250 completed, running loss: 0.0031
Batch 50000/83250 completed, running loss: 0.0031
Batch 60000/83250 completed, running loss: 0.0031
Batch 70000/83250 completed, running loss: 0.0031
Batch 80000/83250 completed, running loss: 0.0032
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 13/50
Train Loss: 0.0032, Train Acc: 0.9989
Val Loss: 0.0188, Val Acc: 0.9955, ROC-AUC: 0.9999
Learning rate after epoch 13: 0.0001
Early stop counter: 1/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0028
Batch 20000/83250 completed, running loss: 0.0029
Batch 30000/83250 completed, running loss: 0.0026
Batch 40000/83250 completed, running loss: 0.0031
Batch 50000/83250 completed, running loss: 0.0031
Batch 60000/83250 completed, running loss: 0.0031
Batch 70000/83250 completed, running loss: 0.0030
Batch 80000/83250 completed, running loss: 0.0030
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 14/50
Train Loss: 0.0031, Train Acc: 0.9990
Val Loss: 0.0174, Val Acc: 0.9960, ROC-AUC: 0.9999
Learning rate after epoch 14: 0.0001
Early stop counter: 2/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0021
Batch 20000/83250 completed, running loss: 0.0025
Batch 30000/83250 completed, running loss: 0.0028
Batch 40000/83250 completed, running loss: 0.0029
Batch 50000/83250 completed, running loss: 0.0029
Batch 60000/83250 completed, running loss: 0.0029
Batch 70000/83250 completed, running loss: 0.0030
Batch 80000/83250 completed, running loss: 0.0029
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 15/50
Train Loss: 0.0030, Train Acc: 0.9991
Val Loss: 0.0191, Val Acc: 0.9954, ROC-AUC: 0.9999
Learning rate after epoch 15: 0.0001
Early stop counter: 3/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0025
Batch 20000/83250 completed, running loss: 0.0023
Batch 30000/83250 completed, running loss: 0.0025
Batch 40000/83250 completed, running loss: 0.0026
Batch 50000/83250 completed, running loss: 0.0027
Batch 60000/83250 completed, running loss: 0.0028
Batch 70000/83250 completed, running loss: 0.0028
Batch 80000/83250 completed, running loss: 0.0028
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 16/50
Train Loss: 0.0028, Train Acc: 0.9992
Val Loss: 0.0179, Val Acc: 0.9959, ROC-AUC: 0.9999
Learning rate after epoch 16: 0.0001
Early stop counter: 4/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0017
Batch 20000/83250 completed, running loss: 0.0025
Batch 30000/83250 completed, running loss: 0.0025
Batch 40000/83250 completed, running loss: 0.0024
Batch 50000/83250 completed, running loss: 0.0026
Batch 60000/83250 completed, running loss: 0.0026
Batch 70000/83250 completed, running loss: 0.0025
Batch 80000/83250 completed, running loss: 0.0025
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 17/50
Train Loss: 0.0025, Train Acc: 0.9992
Val Loss: 0.0187, Val Acc: 0.9959, ROC-AUC: 0.9999
Learning rate after epoch 17: 0.0001
Early stop counter: 5/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0024
Batch 20000/83250 completed, running loss: 0.0023
Batch 30000/83250 completed, running loss: 0.0025
Batch 40000/83250 completed, running loss: 0.0025
Batch 50000/83250 completed, running loss: 0.0024
Batch 60000/83250 completed, running loss: 0.0025
Batch 70000/83250 completed, running loss: 0.0025
Batch 80000/83250 completed, running loss: 0.0025
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 18/50
Train Loss: 0.0024, Train Acc: 0.9992
Val Loss: 0.0174, Val Acc: 0.9960, ROC-AUC: 0.9999
Learning rate after epoch 18: 0.0001
Saved best model with ROC-AUC: 0.9999262809638464
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0017
Batch 20000/83250 completed, running loss: 0.0019
Batch 30000/83250 completed, running loss: 0.0017
Batch 40000/83250 completed, running loss: 0.0018
Batch 50000/83250 completed, running loss: 0.0019
Batch 60000/83250 completed, running loss: 0.0019
Batch 70000/83250 completed, running loss: 0.0019
Batch 80000/83250 completed, running loss: 0.0020
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 19/50
Train Loss: 0.0020, Train Acc: 0.9994
Val Loss: 0.0190, Val Acc: 0.9963, ROC-AUC: 0.9999
Learning rate after epoch 19: 0.0001
Early stop counter: 1/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0022
Batch 20000/83250 completed, running loss: 0.0019
Batch 30000/83250 completed, running loss: 0.0022
Batch 40000/83250 completed, running loss: 0.0020
Batch 50000/83250 completed, running loss: 0.0022
Batch 60000/83250 completed, running loss: 0.0022
Batch 70000/83250 completed, running loss: 0.0022
Batch 80000/83250 completed, running loss: 0.0023
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 20/50
Train Loss: 0.0023, Train Acc: 0.9994
Val Loss: 0.0181, Val Acc: 0.9963, ROC-AUC: 0.9999
Learning rate after epoch 20: 0.0001
Saved best model with ROC-AUC: 0.999930367756104
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0025
Batch 20000/83250 completed, running loss: 0.0021
Batch 30000/83250 completed, running loss: 0.0022
Batch 40000/83250 completed, running loss: 0.0020
Batch 50000/83250 completed, running loss: 0.0020
Batch 60000/83250 completed, running loss: 0.0020
Batch 70000/83250 completed, running loss: 0.0019
Batch 80000/83250 completed, running loss: 0.0020
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 21/50
Train Loss: 0.0020, Train Acc: 0.9994
Val Loss: 0.0190, Val Acc: 0.9962, ROC-AUC: 0.9999
Learning rate after epoch 21: 0.0001
Early stop counter: 1/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0014
Batch 20000/83250 completed, running loss: 0.0014
Batch 30000/83250 completed, running loss: 0.0017
Batch 40000/83250 completed, running loss: 0.0016
Batch 50000/83250 completed, running loss: 0.0017
Batch 60000/83250 completed, running loss: 0.0017
Batch 70000/83250 completed, running loss: 0.0018
Batch 80000/83250 completed, running loss: 0.0018
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 22/50
Train Loss: 0.0018, Train Acc: 0.9995
Val Loss: 0.0236, Val Acc: 0.9958, ROC-AUC: 0.9998
Learning rate after epoch 22: 0.0001
Early stop counter: 2/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0019
Batch 20000/83250 completed, running loss: 0.0016
Batch 30000/83250 completed, running loss: 0.0018
Batch 40000/83250 completed, running loss: 0.0018
Batch 50000/83250 completed, running loss: 0.0018
Batch 60000/83250 completed, running loss: 0.0019
Batch 70000/83250 completed, running loss: 0.0019
Batch 80000/83250 completed, running loss: 0.0018
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 23/50
Train Loss: 0.0018, Train Acc: 0.9995
Val Loss: 0.0222, Val Acc: 0.9962, ROC-AUC: 0.9999
Learning rate after epoch 23: 5e-05
Early stop counter: 3/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0011
Batch 20000/83250 completed, running loss: 0.0015
Batch 30000/83250 completed, running loss: 0.0013
Batch 40000/83250 completed, running loss: 0.0013
Batch 50000/83250 completed, running loss: 0.0014
Batch 60000/83250 completed, running loss: 0.0013
Batch 70000/83250 completed, running loss: 0.0013
Batch 80000/83250 completed, running loss: 0.0013
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 24/50
Train Loss: 0.0013, Train Acc: 0.9997
Val Loss: 0.0202, Val Acc: 0.9966, ROC-AUC: 0.9999
Learning rate after epoch 24: 5e-05
Saved best model with ROC-AUC: 0.9999338221318745
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0002
Batch 20000/83250 completed, running loss: 0.0005
Batch 30000/83250 completed, running loss: 0.0004
Batch 40000/83250 completed, running loss: 0.0005
Batch 50000/83250 completed, running loss: 0.0004
Batch 60000/83250 completed, running loss: 0.0004
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 25/50
Train Loss: 0.0005, Train Acc: 0.9998
Val Loss: 0.0261, Val Acc: 0.9967, ROC-AUC: 0.9998
Learning rate after epoch 25: 5e-05
Early stop counter: 1/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0009
Batch 20000/83250 completed, running loss: 0.0008
Batch 30000/83250 completed, running loss: 0.0006
Batch 40000/83250 completed, running loss: 0.0007
Batch 50000/83250 completed, running loss: 0.0008
Batch 60000/83250 completed, running loss: 0.0009
Batch 70000/83250 completed, running loss: 0.0008
Batch 80000/83250 completed, running loss: 0.0008
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 26/50
Train Loss: 0.0008, Train Acc: 0.9998
Val Loss: 0.0251, Val Acc: 0.9965, ROC-AUC: 0.9999
Learning rate after epoch 26: 5e-05
Early stop counter: 2/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0008
Batch 20000/83250 completed, running loss: 0.0006
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0004
Batch 50000/83250 completed, running loss: 0.0006
Batch 60000/83250 completed, running loss: 0.0006
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0006
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 27/50
Train Loss: 0.0006, Train Acc: 0.9998
Val Loss: 0.0279, Val Acc: 0.9963, ROC-AUC: 0.9998
Learning rate after epoch 27: 5e-05
Early stop counter: 3/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0001
Batch 20000/83250 completed, running loss: 0.0003
Batch 30000/83250 completed, running loss: 0.0003
Batch 40000/83250 completed, running loss: 0.0003
Batch 50000/83250 completed, running loss: 0.0003
Batch 60000/83250 completed, running loss: 0.0004
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 28/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0270, Val Acc: 0.9966, ROC-AUC: 0.9998
Learning rate after epoch 28: 5e-05
Early stop counter: 4/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0006
Batch 20000/83250 completed, running loss: 0.0005
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0004
Batch 50000/83250 completed, running loss: 0.0005
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 29/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0254, Val Acc: 0.9964, ROC-AUC: 0.9999
Learning rate after epoch 29: 5e-05
Early stop counter: 5/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0006
Batch 20000/83250 completed, running loss: 0.0005
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0005
Batch 50000/83250 completed, running loss: 0.0004
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 30/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0324, Val Acc: 0.9963, ROC-AUC: 0.9998
Learning rate after epoch 30: 5e-05
Early stop counter: 6/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0003
Batch 20000/83250 completed, running loss: 0.0003
Batch 30000/83250 completed, running loss: 0.0004
Batch 40000/83250 completed, running loss: 0.0006
Batch 50000/83250 completed, running loss: 0.0007
Batch 60000/83250 completed, running loss: 0.0007
Batch 70000/83250 completed, running loss: 0.0007
Batch 80000/83250 completed, running loss: 0.0007
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 31/50
Train Loss: 0.0007, Train Acc: 0.9998
Val Loss: 0.0329, Val Acc: 0.9962, ROC-AUC: 0.9997
Learning rate after epoch 31: 5e-05
Early stop counter: 7/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0006
Batch 20000/83250 completed, running loss: 0.0007
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0005
Batch 50000/83250 completed, running loss: 0.0005
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0006
Batch 80000/83250 completed, running loss: 0.0006
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 32/50
Train Loss: 0.0006, Train Acc: 0.9998
Val Loss: 0.0300, Val Acc: 0.9965, ROC-AUC: 0.9999
Learning rate after epoch 32: 5e-05
Early stop counter: 8/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0009
Batch 20000/83250 completed, running loss: 0.0007
Batch 30000/83250 completed, running loss: 0.0006
Batch 40000/83250 completed, running loss: 0.0006
Batch 50000/83250 completed, running loss: 0.0006
Batch 60000/83250 completed, running loss: 0.0006
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0006
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 33/50
Train Loss: 0.0006, Train Acc: 0.9999
Val Loss: 0.0308, Val Acc: 0.9966, ROC-AUC: 0.9999
Learning rate after epoch 33: 5e-05
Early stop counter: 9/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0009
Batch 20000/83250 completed, running loss: 0.0007
Batch 30000/83250 completed, running loss: 0.0007
Batch 40000/83250 completed, running loss: 0.0007
Batch 50000/83250 completed, running loss: 0.0006
Batch 60000/83250 completed, running loss: 0.0006
Batch 70000/83250 completed, running loss: 0.0006
Batch 80000/83250 completed, running loss: 0.0007
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 34/50
Train Loss: 0.0007, Train Acc: 0.9998
Val Loss: 0.0277, Val Acc: 0.9965, ROC-AUC: 0.9999
Learning rate after epoch 34: 5e-05
Early stop counter: 10/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0009
Batch 20000/83250 completed, running loss: 0.0010
Batch 30000/83250 completed, running loss: 0.0010
Batch 40000/83250 completed, running loss: 0.0009
Batch 50000/83250 completed, running loss: 0.0008
Batch 60000/83250 completed, running loss: 0.0008
Batch 70000/83250 completed, running loss: 0.0007
Batch 80000/83250 completed, running loss: 0.0007
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 35/50
Train Loss: 0.0007, Train Acc: 0.9999
Val Loss: 0.0332, Val Acc: 0.9963, ROC-AUC: 0.9997
Learning rate after epoch 35: 5e-05
Early stop counter: 11/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0003
Batch 20000/83250 completed, running loss: 0.0006
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0006
Batch 50000/83250 completed, running loss: 0.0007
Batch 60000/83250 completed, running loss: 0.0007
Batch 70000/83250 completed, running loss: 0.0006
Batch 80000/83250 completed, running loss: 0.0006
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 36/50
Train Loss: 0.0006, Train Acc: 0.9998
Val Loss: 0.0305, Val Acc: 0.9965, ROC-AUC: 0.9999
Learning rate after epoch 36: 5e-05
Early stop counter: 12/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0006
Batch 20000/83250 completed, running loss: 0.0003
Batch 30000/83250 completed, running loss: 0.0003
Batch 40000/83250 completed, running loss: 0.0003
Batch 50000/83250 completed, running loss: 0.0003
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 37/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0345, Val Acc: 0.9965, ROC-AUC: 0.9997
Learning rate after epoch 37: 5e-05
Early stop counter: 13/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0005
Batch 20000/83250 completed, running loss: 0.0006
Batch 30000/83250 completed, running loss: 0.0007
Batch 40000/83250 completed, running loss: 0.0007
Batch 50000/83250 completed, running loss: 0.0005
Batch 60000/83250 completed, running loss: 0.0006
Batch 70000/83250 completed, running loss: 0.0006
Batch 80000/83250 completed, running loss: 0.0006
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 38/50
Train Loss: 0.0006, Train Acc: 0.9999
Val Loss: 0.0322, Val Acc: 0.9969, ROC-AUC: 0.9998
Learning rate after epoch 38: 5e-05
Early stop counter: 14/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0004
Batch 20000/83250 completed, running loss: 0.0003
Batch 30000/83250 completed, running loss: 0.0003
Batch 40000/83250 completed, running loss: 0.0004
Batch 50000/83250 completed, running loss: 0.0005
Batch 60000/83250 completed, running loss: 0.0006
Batch 70000/83250 completed, running loss: 0.0006
Batch 80000/83250 completed, running loss: 0.0006
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 39/50
Train Loss: 0.0007, Train Acc: 0.9998
Val Loss: 0.0320, Val Acc: 0.9965, ROC-AUC: 0.9999
Learning rate after epoch 39: 2.5e-05
Early stop counter: 15/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0004
Batch 20000/83250 completed, running loss: 0.0003
Batch 30000/83250 completed, running loss: 0.0004
Batch 40000/83250 completed, running loss: 0.0003
Batch 50000/83250 completed, running loss: 0.0004
Batch 60000/83250 completed, running loss: 0.0003
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 40/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 0.0385, Val Acc: 0.9965, ROC-AUC: 0.9996
Learning rate after epoch 40: 2.5e-05
Early stop counter: 16/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0001
Batch 20000/83250 completed, running loss: 0.0003
Batch 30000/83250 completed, running loss: 0.0004
Batch 40000/83250 completed, running loss: 0.0003
Batch 50000/83250 completed, running loss: 0.0004
Batch 60000/83250 completed, running loss: 0.0004
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 41/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 0.0333, Val Acc: 0.9963, ROC-AUC: 0.9999
Learning rate after epoch 41: 2.5e-05
Early stop counter: 17/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0012
Batch 20000/83250 completed, running loss: 0.0008
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0005
Batch 50000/83250 completed, running loss: 0.0006
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 42/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0358, Val Acc: 0.9965, ROC-AUC: 0.9999
Learning rate after epoch 42: 2.5e-05
Early stop counter: 18/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0002
Batch 20000/83250 completed, running loss: 0.0002
Batch 30000/83250 completed, running loss: 0.0003
Batch 40000/83250 completed, running loss: 0.0003
Batch 50000/83250 completed, running loss: 0.0003
Batch 60000/83250 completed, running loss: 0.0003
Batch 70000/83250 completed, running loss: 0.0003
Batch 80000/83250 completed, running loss: 0.0003
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 43/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 0.0370, Val Acc: 0.9962, ROC-AUC: 0.9997
Learning rate after epoch 43: 2.5e-05
Early stop counter: 19/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0002
Batch 20000/83250 completed, running loss: 0.0005
Batch 30000/83250 completed, running loss: 0.0004
Batch 40000/83250 completed, running loss: 0.0004
Batch 50000/83250 completed, running loss: 0.0004
Batch 60000/83250 completed, running loss: 0.0003
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 44/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 0.0363, Val Acc: 0.9964, ROC-AUC: 0.9999
Learning rate after epoch 44: 2.5e-05
Early stop counter: 20/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0008
Batch 20000/83250 completed, running loss: 0.0005
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0004
Batch 50000/83250 completed, running loss: 0.0004
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 45/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0369, Val Acc: 0.9966, ROC-AUC: 0.9999
Learning rate after epoch 45: 2.5e-05
Early stop counter: 21/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0004
Batch 20000/83250 completed, running loss: 0.0005
Batch 30000/83250 completed, running loss: 0.0005
Batch 40000/83250 completed, running loss: 0.0005
Batch 50000/83250 completed, running loss: 0.0005
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 46/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0359, Val Acc: 0.9966, ROC-AUC: 0.9999
Learning rate after epoch 46: 2.5e-05
Early stop counter: 22/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0003
Batch 20000/83250 completed, running loss: 0.0002
Batch 30000/83250 completed, running loss: 0.0002
Batch 40000/83250 completed, running loss: 0.0003
Batch 50000/83250 completed, running loss: 0.0005
Batch 60000/83250 completed, running loss: 0.0006
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0005
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 47/50
Train Loss: 0.0005, Train Acc: 0.9999
Val Loss: 0.0411, Val Acc: 0.9966, ROC-AUC: 0.9996
Learning rate after epoch 47: 2.5e-05
Early stop counter: 23/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0002
Batch 20000/83250 completed, running loss: 0.0004
Batch 30000/83250 completed, running loss: 0.0003
Batch 40000/83250 completed, running loss: 0.0004
Batch 50000/83250 completed, running loss: 0.0003
Batch 60000/83250 completed, running loss: 0.0003
Batch 70000/83250 completed, running loss: 0.0003
Batch 80000/83250 completed, running loss: 0.0003
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 48/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 0.0405, Val Acc: 0.9965, ROC-AUC: 0.9996
Learning rate after epoch 48: 2.5e-05
Early stop counter: 24/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0009
Batch 20000/83250 completed, running loss: 0.0008
Batch 30000/83250 completed, running loss: 0.0009
Batch 40000/83250 completed, running loss: 0.0007
Batch 50000/83250 completed, running loss: 0.0006
Batch 60000/83250 completed, running loss: 0.0005
Batch 70000/83250 completed, running loss: 0.0005
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 49/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 0.0333, Val Acc: 0.9963, ROC-AUC: 0.9999
Learning rate after epoch 49: 2.5e-05
Early stop counter: 25/30
Starting training epoch with 83250 batches
Batch 10000/83250 completed, running loss: 0.0002
Batch 20000/83250 completed, running loss: 0.0002
Batch 30000/83250 completed, running loss: 0.0002
Batch 40000/83250 completed, running loss: 0.0002
Batch 50000/83250 completed, running loss: 0.0003
Batch 60000/83250 completed, running loss: 0.0004
Batch 70000/83250 completed, running loss: 0.0004
Batch 80000/83250 completed, running loss: 0.0004
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Epoch 50/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 0.0356, Val Acc: 0.9966, ROC-AUC: 0.9999
Learning rate after epoch 50: 2.5e-05
Early stop counter: 26/30
Training completed. Best Val ROC-AUC: 0.9999338221318745
Loading best model for final evaluation
Evaluating on train set
Starting evaluation with 83250 batches
Evaluation batch 10000/83250 completed
Evaluation batch 20000/83250 completed
Evaluation batch 30000/83250 completed
Evaluation batch 40000/83250 completed
Evaluation batch 50000/83250 completed
Evaluation batch 60000/83250 completed
Evaluation batch 70000/83250 completed
Evaluation batch 80000/83250 completed
Evaluating on validation set
Starting evaluation with 11893 batches
Evaluation batch 10000/11893 completed
Evaluating on test set
Starting evaluation with 40776 batches
Evaluation batch 10000/40776 completed
Evaluation batch 20000/40776 completed
Evaluation batch 30000/40776 completed
Evaluation batch 40000/40776 completed

Final Metrics:

Train Metrics:
Loss: 0.0000
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
ROC-AUC: 1.0000
Specificity: 1.0000
F1-Score: 1.0000

Validation Metrics:
Loss: 0.0202
Accuracy: 0.9966
Precision: 0.9972
Recall: 0.9963
ROC-AUC: 0.9999
Specificity: 0.9970
F1-Score: 0.9968

Test Metrics:
Loss: 0.0226
Accuracy: 0.9966
Precision: 0.9971
Recall: 0.9964
ROC-AUC: 0.9999
Specificity: 0.9968
F1-Score: 0.9968
