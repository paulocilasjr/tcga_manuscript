Setting random seed to 100
Using device: cuda
Loading CSV from ./../../../../trident/TCGA_BRCA/convert_h5_to_csv/csv_files/tcga_patches_with_labels.csv
Performing stratified split based on sample_name and label
Preparing dataset with 281166 samples
Extracting feature
Normalizing embeddings
Dataset ready with 281166 samples
Preparing dataset with 64132 samples
Extracting feature
Normalizing embeddings
Dataset ready with 64132 samples
Preparing dataset with 198372 samples
Extracting feature
Normalizing embeddings
Dataset ready with 198372 samples
Train dataset size: 281166
Validation dataset size: 64132
Test dataset size: 198372
Input dimension: 1536
Model initialized and moved to cuda
Optimizer and scheduler initialized with learning rate: 0.0001
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0669
Batch 20000/70292 completed, running loss: 0.0480
Batch 30000/70292 completed, running loss: 0.0399
Batch 40000/70292 completed, running loss: 0.0353
Batch 50000/70292 completed, running loss: 0.0318
Batch 60000/70292 completed, running loss: 0.0294
Batch 70000/70292 completed, running loss: 0.0274
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 1/50
Train Loss: 0.0273, Train Acc: 0.9896
Val Loss: 7.8197, Val Acc: 0.2493, ROC-AUC: 0.1838
Learning rate after epoch 1: 0.0001
Saved best model with ROC-AUC: 0.18380204070511774
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0130
Batch 20000/70292 completed, running loss: 0.0126
Batch 30000/70292 completed, running loss: 0.0126
Batch 40000/70292 completed, running loss: 0.0124
Batch 50000/70292 completed, running loss: 0.0123
Batch 60000/70292 completed, running loss: 0.0122
Batch 70000/70292 completed, running loss: 0.0122
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 2/50
Train Loss: 0.0121, Train Acc: 0.9955
Val Loss: 10.1929, Val Acc: 0.1772, ROC-AUC: 0.0984
Learning rate after epoch 2: 0.0001
Early stop counter: 1/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0092
Batch 20000/70292 completed, running loss: 0.0086
Batch 30000/70292 completed, running loss: 0.0085
Batch 40000/70292 completed, running loss: 0.0087
Batch 50000/70292 completed, running loss: 0.0085
Batch 60000/70292 completed, running loss: 0.0084
Batch 70000/70292 completed, running loss: 0.0084
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 3/50
Train Loss: 0.0084, Train Acc: 0.9969
Val Loss: 10.1916, Val Acc: 0.2445, ROC-AUC: 0.1875
Learning rate after epoch 3: 0.0001
Saved best model with ROC-AUC: 0.18753913960852003
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0067
Batch 20000/70292 completed, running loss: 0.0064
Batch 30000/70292 completed, running loss: 0.0063
Batch 40000/70292 completed, running loss: 0.0065
Batch 50000/70292 completed, running loss: 0.0067
Batch 60000/70292 completed, running loss: 0.0067
Batch 70000/70292 completed, running loss: 0.0066
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 4/50
Train Loss: 0.0066, Train Acc: 0.9976
Val Loss: 11.4205, Val Acc: 0.1969, ROC-AUC: 0.1293
Learning rate after epoch 4: 0.0001
Early stop counter: 1/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0054
Batch 20000/70292 completed, running loss: 0.0051
Batch 30000/70292 completed, running loss: 0.0049
Batch 40000/70292 completed, running loss: 0.0050
Batch 50000/70292 completed, running loss: 0.0050
Batch 60000/70292 completed, running loss: 0.0051
Batch 70000/70292 completed, running loss: 0.0053
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 5/50
Train Loss: 0.0053, Train Acc: 0.9981
Val Loss: 13.0225, Val Acc: 0.2130, ROC-AUC: 0.1475
Learning rate after epoch 5: 0.0001
Early stop counter: 2/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0038
Batch 20000/70292 completed, running loss: 0.0041
Batch 30000/70292 completed, running loss: 0.0040
Batch 40000/70292 completed, running loss: 0.0041
Batch 50000/70292 completed, running loss: 0.0043
Batch 60000/70292 completed, running loss: 0.0044
Batch 70000/70292 completed, running loss: 0.0045
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 6/50
Train Loss: 0.0045, Train Acc: 0.9985
Val Loss: 14.3866, Val Acc: 0.2028, ROC-AUC: 0.1608
Learning rate after epoch 6: 0.0001
Early stop counter: 3/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0036
Batch 20000/70292 completed, running loss: 0.0036
Batch 30000/70292 completed, running loss: 0.0036
Batch 40000/70292 completed, running loss: 0.0039
Batch 50000/70292 completed, running loss: 0.0039
Batch 60000/70292 completed, running loss: 0.0039
Batch 70000/70292 completed, running loss: 0.0039
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 7/50
Train Loss: 0.0039, Train Acc: 0.9986
Val Loss: 20.7280, Val Acc: 0.1589, ROC-AUC: 0.0945
Learning rate after epoch 7: 0.0001
Early stop counter: 4/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0035
Batch 20000/70292 completed, running loss: 0.0034
Batch 30000/70292 completed, running loss: 0.0034
Batch 40000/70292 completed, running loss: 0.0033
Batch 50000/70292 completed, running loss: 0.0034
Batch 60000/70292 completed, running loss: 0.0035
Batch 70000/70292 completed, running loss: 0.0035
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 8/50
Train Loss: 0.0035, Train Acc: 0.9988
Val Loss: 18.0741, Val Acc: 0.2085, ROC-AUC: 0.1646
Learning rate after epoch 8: 0.0001
Early stop counter: 5/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0028
Batch 20000/70292 completed, running loss: 0.0029
Batch 30000/70292 completed, running loss: 0.0029
Batch 40000/70292 completed, running loss: 0.0027
Batch 50000/70292 completed, running loss: 0.0029
Batch 60000/70292 completed, running loss: 0.0029
Batch 70000/70292 completed, running loss: 0.0031
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 9/50
Train Loss: 0.0031, Train Acc: 0.9990
Val Loss: 20.4297, Val Acc: 0.1544, ROC-AUC: 0.0936
Learning rate after epoch 9: 0.0001
Early stop counter: 6/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0026
Batch 20000/70292 completed, running loss: 0.0024
Batch 30000/70292 completed, running loss: 0.0024
Batch 40000/70292 completed, running loss: 0.0027
Batch 50000/70292 completed, running loss: 0.0027
Batch 60000/70292 completed, running loss: 0.0027
Batch 70000/70292 completed, running loss: 0.0027
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 10/50
Train Loss: 0.0027, Train Acc: 0.9991
Val Loss: 22.5796, Val Acc: 0.1524, ROC-AUC: 0.0723
Learning rate after epoch 10: 0.0001
Early stop counter: 7/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0024
Batch 20000/70292 completed, running loss: 0.0024
Batch 30000/70292 completed, running loss: 0.0023
Batch 40000/70292 completed, running loss: 0.0023
Batch 50000/70292 completed, running loss: 0.0024
Batch 60000/70292 completed, running loss: 0.0024
Batch 70000/70292 completed, running loss: 0.0025
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 11/50
Train Loss: 0.0025, Train Acc: 0.9992
Val Loss: 21.3600, Val Acc: 0.1910, ROC-AUC: 0.1407
Learning rate after epoch 11: 0.0001
Early stop counter: 8/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0026
Batch 20000/70292 completed, running loss: 0.0021
Batch 30000/70292 completed, running loss: 0.0022
Batch 40000/70292 completed, running loss: 0.0022
Batch 50000/70292 completed, running loss: 0.0022
Batch 60000/70292 completed, running loss: 0.0023
Batch 70000/70292 completed, running loss: 0.0023
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 12/50
Train Loss: 0.0023, Train Acc: 0.9993
Val Loss: 21.8430, Val Acc: 0.1797, ROC-AUC: 0.1264
Learning rate after epoch 12: 0.0001
Early stop counter: 9/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0017
Batch 20000/70292 completed, running loss: 0.0015
Batch 30000/70292 completed, running loss: 0.0016
Batch 40000/70292 completed, running loss: 0.0018
Batch 50000/70292 completed, running loss: 0.0020
Batch 60000/70292 completed, running loss: 0.0019
Batch 70000/70292 completed, running loss: 0.0020
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 13/50
Train Loss: 0.0020, Train Acc: 0.9993
Val Loss: 23.4357, Val Acc: 0.1842, ROC-AUC: 0.1201
Learning rate after epoch 13: 0.0001
Early stop counter: 10/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0018
Batch 20000/70292 completed, running loss: 0.0018
Batch 30000/70292 completed, running loss: 0.0019
Batch 40000/70292 completed, running loss: 0.0021
Batch 50000/70292 completed, running loss: 0.0020
Batch 60000/70292 completed, running loss: 0.0021
Batch 70000/70292 completed, running loss: 0.0021
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 14/50
Train Loss: 0.0021, Train Acc: 0.9994
Val Loss: 23.6498, Val Acc: 0.1874, ROC-AUC: 0.1269
Learning rate after epoch 14: 0.0001
Early stop counter: 11/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0015
Batch 20000/70292 completed, running loss: 0.0014
Batch 30000/70292 completed, running loss: 0.0014
Batch 40000/70292 completed, running loss: 0.0015
Batch 50000/70292 completed, running loss: 0.0016
Batch 60000/70292 completed, running loss: 0.0015
Batch 70000/70292 completed, running loss: 0.0016
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 15/50
Train Loss: 0.0016, Train Acc: 0.9995
Val Loss: 30.4933, Val Acc: 0.1609, ROC-AUC: 0.1033
Learning rate after epoch 15: 0.0001
Early stop counter: 12/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0019
Batch 20000/70292 completed, running loss: 0.0017
Batch 30000/70292 completed, running loss: 0.0016
Batch 40000/70292 completed, running loss: 0.0015
Batch 50000/70292 completed, running loss: 0.0015
Batch 60000/70292 completed, running loss: 0.0016
Batch 70000/70292 completed, running loss: 0.0017
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 16/50
Train Loss: 0.0017, Train Acc: 0.9994
Val Loss: 32.0188, Val Acc: 0.1633, ROC-AUC: 0.1085
Learning rate after epoch 16: 0.0001
Early stop counter: 13/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0012
Batch 20000/70292 completed, running loss: 0.0013
Batch 30000/70292 completed, running loss: 0.0016
Batch 40000/70292 completed, running loss: 0.0016
Batch 50000/70292 completed, running loss: 0.0015
Batch 60000/70292 completed, running loss: 0.0015
Batch 70000/70292 completed, running loss: 0.0015
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 17/50
Train Loss: 0.0015, Train Acc: 0.9996
Val Loss: 31.1647, Val Acc: 0.1815, ROC-AUC: 0.1357
Learning rate after epoch 17: 0.0001
Early stop counter: 14/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0012
Batch 20000/70292 completed, running loss: 0.0015
Batch 30000/70292 completed, running loss: 0.0014
Batch 40000/70292 completed, running loss: 0.0015
Batch 50000/70292 completed, running loss: 0.0015
Batch 60000/70292 completed, running loss: 0.0015
Batch 70000/70292 completed, running loss: 0.0015
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 18/50
Train Loss: 0.0015, Train Acc: 0.9996
Val Loss: 35.0589, Val Acc: 0.1566, ROC-AUC: 0.0931
Learning rate after epoch 18: 0.0001
Early stop counter: 15/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0020
Batch 20000/70292 completed, running loss: 0.0016
Batch 30000/70292 completed, running loss: 0.0017
Batch 40000/70292 completed, running loss: 0.0016
Batch 50000/70292 completed, running loss: 0.0016
Batch 60000/70292 completed, running loss: 0.0016
Batch 70000/70292 completed, running loss: 0.0016
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 19/50
Train Loss: 0.0015, Train Acc: 0.9995
Val Loss: 32.5679, Val Acc: 0.1804, ROC-AUC: 0.1137
Learning rate after epoch 19: 5e-05
Early stop counter: 16/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0008
Batch 20000/70292 completed, running loss: 0.0007
Batch 30000/70292 completed, running loss: 0.0007
Batch 40000/70292 completed, running loss: 0.0007
Batch 50000/70292 completed, running loss: 0.0007
Batch 60000/70292 completed, running loss: 0.0006
Batch 70000/70292 completed, running loss: 0.0007
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 20/50
Train Loss: 0.0006, Train Acc: 0.9998
Val Loss: 39.4707, Val Acc: 0.1627, ROC-AUC: 0.1028
Learning rate after epoch 20: 5e-05
Early stop counter: 17/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0003
Batch 20000/70292 completed, running loss: 0.0004
Batch 30000/70292 completed, running loss: 0.0004
Batch 40000/70292 completed, running loss: 0.0003
Batch 50000/70292 completed, running loss: 0.0003
Batch 60000/70292 completed, running loss: 0.0003
Batch 70000/70292 completed, running loss: 0.0003
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 21/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 47.0526, Val Acc: 0.1514, ROC-AUC: 0.0923
Learning rate after epoch 21: 5e-05
Early stop counter: 18/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0001
Batch 20000/70292 completed, running loss: 0.0001
Batch 30000/70292 completed, running loss: 0.0003
Batch 40000/70292 completed, running loss: 0.0004
Batch 50000/70292 completed, running loss: 0.0003
Batch 60000/70292 completed, running loss: 0.0004
Batch 70000/70292 completed, running loss: 0.0004
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 22/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 51.5103, Val Acc: 0.1426, ROC-AUC: 0.0830
Learning rate after epoch 22: 5e-05
Early stop counter: 19/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0003
Batch 20000/70292 completed, running loss: 0.0002
Batch 30000/70292 completed, running loss: 0.0002
Batch 40000/70292 completed, running loss: 0.0002
Batch 50000/70292 completed, running loss: 0.0002
Batch 60000/70292 completed, running loss: 0.0002
Batch 70000/70292 completed, running loss: 0.0002
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 23/50
Train Loss: 0.0002, Train Acc: 0.9999
Val Loss: 54.6122, Val Acc: 0.1371, ROC-AUC: 0.0725
Learning rate after epoch 23: 5e-05
Early stop counter: 20/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0003
Batch 20000/70292 completed, running loss: 0.0002
Batch 30000/70292 completed, running loss: 0.0004
Batch 40000/70292 completed, running loss: 0.0003
Batch 50000/70292 completed, running loss: 0.0004
Batch 60000/70292 completed, running loss: 0.0004
Batch 70000/70292 completed, running loss: 0.0004
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 24/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 60.0674, Val Acc: 0.1227, ROC-AUC: 0.0651
Learning rate after epoch 24: 5e-05
Early stop counter: 21/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0008
Batch 20000/70292 completed, running loss: 0.0006
Batch 30000/70292 completed, running loss: 0.0005
Batch 40000/70292 completed, running loss: 0.0004
Batch 50000/70292 completed, running loss: 0.0004
Batch 60000/70292 completed, running loss: 0.0004
Batch 70000/70292 completed, running loss: 0.0004
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 25/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 60.0523, Val Acc: 0.1254, ROC-AUC: 0.0752
Learning rate after epoch 25: 5e-05
Early stop counter: 22/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0000
Batch 20000/70292 completed, running loss: 0.0001
Batch 30000/70292 completed, running loss: 0.0002
Batch 40000/70292 completed, running loss: 0.0002
Batch 50000/70292 completed, running loss: 0.0002
Batch 60000/70292 completed, running loss: 0.0003
Batch 70000/70292 completed, running loss: 0.0003
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 26/50
Train Loss: 0.0003, Train Acc: 1.0000
Val Loss: 66.8490, Val Acc: 0.1281, ROC-AUC: 0.0791
Learning rate after epoch 26: 5e-05
Early stop counter: 23/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0004
Batch 20000/70292 completed, running loss: 0.0005
Batch 30000/70292 completed, running loss: 0.0004
Batch 40000/70292 completed, running loss: 0.0004
Batch 50000/70292 completed, running loss: 0.0003
Batch 60000/70292 completed, running loss: 0.0003
Batch 70000/70292 completed, running loss: 0.0003
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 27/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 73.4334, Val Acc: 0.1248, ROC-AUC: 0.0637
Learning rate after epoch 27: 5e-05
Early stop counter: 24/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0005
Batch 20000/70292 completed, running loss: 0.0003
Batch 30000/70292 completed, running loss: 0.0003
Batch 40000/70292 completed, running loss: 0.0002
Batch 50000/70292 completed, running loss: 0.0003
Batch 60000/70292 completed, running loss: 0.0003
Batch 70000/70292 completed, running loss: 0.0003
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 28/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 71.6417, Val Acc: 0.1228, ROC-AUC: 0.0618
Learning rate after epoch 28: 5e-05
Early stop counter: 25/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0000
Batch 20000/70292 completed, running loss: 0.0000
Batch 30000/70292 completed, running loss: 0.0000
Batch 40000/70292 completed, running loss: 0.0004
Batch 50000/70292 completed, running loss: 0.0004
Batch 60000/70292 completed, running loss: 0.0004
Batch 70000/70292 completed, running loss: 0.0004
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 29/50
Train Loss: 0.0004, Train Acc: 0.9999
Val Loss: 76.6065, Val Acc: 0.1221, ROC-AUC: 0.0652
Learning rate after epoch 29: 5e-05
Early stop counter: 26/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0003
Batch 20000/70292 completed, running loss: 0.0003
Batch 30000/70292 completed, running loss: 0.0002
Batch 40000/70292 completed, running loss: 0.0002
Batch 50000/70292 completed, running loss: 0.0002
Batch 60000/70292 completed, running loss: 0.0002
Batch 70000/70292 completed, running loss: 0.0003
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 30/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 81.7941, Val Acc: 0.1086, ROC-AUC: 0.0557
Learning rate after epoch 30: 5e-05
Early stop counter: 27/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0000
Batch 20000/70292 completed, running loss: 0.0003
Batch 30000/70292 completed, running loss: 0.0004
Batch 40000/70292 completed, running loss: 0.0004
Batch 50000/70292 completed, running loss: 0.0004
Batch 60000/70292 completed, running loss: 0.0004
Batch 70000/70292 completed, running loss: 0.0003
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 31/50
Train Loss: 0.0003, Train Acc: 0.9999
Val Loss: 84.3253, Val Acc: 0.1259, ROC-AUC: 0.0636
Learning rate after epoch 31: 5e-05
Early stop counter: 28/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0000
Batch 20000/70292 completed, running loss: 0.0002
Batch 30000/70292 completed, running loss: 0.0002
Batch 40000/70292 completed, running loss: 0.0002
Batch 50000/70292 completed, running loss: 0.0002
Batch 60000/70292 completed, running loss: 0.0002
Batch 70000/70292 completed, running loss: 0.0002
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 32/50
Train Loss: 0.0002, Train Acc: 0.9999
Val Loss: 88.6207, Val Acc: 0.1257, ROC-AUC: 0.0650
Learning rate after epoch 32: 5e-05
Early stop counter: 29/30
Starting training epoch with 70292 batches
Batch 10000/70292 completed, running loss: 0.0003
Batch 20000/70292 completed, running loss: 0.0003
Batch 30000/70292 completed, running loss: 0.0002
Batch 40000/70292 completed, running loss: 0.0002
Batch 50000/70292 completed, running loss: 0.0002
Batch 60000/70292 completed, running loss: 0.0002
Batch 70000/70292 completed, running loss: 0.0002
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Epoch 33/50
Train Loss: 0.0002, Train Acc: 1.0000
Val Loss: 88.5143, Val Acc: 0.1240, ROC-AUC: 0.0701
Learning rate after epoch 33: 5e-05
Early stop counter: 30/30
Early stopping triggered
Training completed. Best Val ROC-AUC: 0.18753913960852003
Loading best model for final evaluation
Evaluating on train set
Starting evaluation with 70292 batches
Evaluation batch 10000/70292 completed
Evaluation batch 20000/70292 completed
Evaluation batch 30000/70292 completed
Evaluation batch 40000/70292 completed
Evaluation batch 50000/70292 completed
Evaluation batch 60000/70292 completed
Evaluation batch 70000/70292 completed
Evaluating on validation set
Starting evaluation with 16033 batches
Evaluation batch 10000/16033 completed
Evaluating on test set
Starting evaluation with 49593 batches
Evaluation batch 10000/49593 completed
Evaluation batch 20000/49593 completed
Evaluation batch 30000/49593 completed
Evaluation batch 40000/49593 completed

Final Metrics:

Train Metrics:
Loss: 0.0041
Accuracy: 0.9985
Precision: 0.9982
Recall: 0.9991
ROC-AUC: 1.0000
Specificity: 0.9978
F1-Score: 0.9986

Validation Metrics:
Loss: 10.1916
Accuracy: 0.2445
Precision: 0.2338
Recall: 0.2640
ROC-AUC: 0.1875
Specificity: 0.2271
F1-Score: 0.2480

Test Metrics:
Loss: 3.5597
Accuracy: 0.6642
Precision: 0.6647
Recall: 0.6450
ROC-AUC: 0.7193
Specificity: 0.6829
F1-Score: 0.6547
